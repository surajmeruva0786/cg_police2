{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Cybercrime Intelligence Newspaper Agent\n",
    "\n",
    "This notebook implements a simple autonomous AI agent that monitors news sources for cybercrime-related incidents. The agent automatically fetches newspaper articles, identifies fraud and cybercrime mentions, summarizes key information, and generates a daily intelligence brief for law enforcement agencies. This is a **Stage-1 prototype** focused on clarity and simplicity‚Äîdesigned to evolve into a production-ready system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an AI Agent?\n",
    "\n",
    "Think of an AI agent as a **smart assistant that can act on its own**. Unlike a simple chatbot that just answers questions, an agent:\n",
    "\n",
    "1. **Perceives** its environment (reads news, checks data)\n",
    "2. **Thinks** about what it sees (analyzes, filters, decides)\n",
    "3. **Acts** on its analysis (summarizes, reports, alerts)\n",
    "4. **Repeats** this cycle autonomously\n",
    "\n",
    "In Ed Donner's framework, an agent has:\n",
    "- **Goals** (find cybercrime news)\n",
    "- **Tools** (web scraping, LLM reasoning)\n",
    "- **Memory** (what it has already processed)\n",
    "- **Actions** (generate reports)\n",
    "\n",
    "Our agent is simple but powerful: it replaces hours of manual news monitoring with an automated, intelligent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import re\n",
    "\n",
    "# For LLM integration - using Ollama with local Llama 3.2 model\n",
    "try:\n",
    "    import ollama\n",
    "    # Test if Ollama is running and model is available\n",
    "    try:\n",
    "        ollama.chat(model='llama3.2:latest', messages=[{'role': 'user', 'content': 'test'}])\n",
    "        LLM_AVAILABLE = True\n",
    "        print(\"‚úÖ Ollama connected successfully with llama3.2:latest model\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Ollama error: {e}\")\n",
    "        print(\"   Make sure Ollama is running and llama3.2:latest model is downloaded\")\n",
    "        print(\"   Run: ollama pull llama3.2:latest\")\n",
    "        LLM_AVAILABLE = False\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Ollama library not installed. Install with: pip install ollama\")\n",
    "    print(\"   Will use mock summaries for demo.\")\n",
    "    LLM_AVAILABLE = False\n",
    "\n",
    "print(\"\\n‚úÖ Libraries imported successfully\")\n",
    "print(f\"üìÖ Today's date: {datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent Loop Explained\n",
    "\n",
    "Our agent follows a simple four-step cycle:\n",
    "\n",
    "### 1Ô∏è‚É£ **FETCH** (Perception)\n",
    "- Retrieve news headlines from RSS feeds or static sources\n",
    "- Parse the content into structured data\n",
    "\n",
    "### 2Ô∏è‚É£ **THINK** (Reasoning)\n",
    "- Filter articles using cybercrime keywords\n",
    "- Identify which news items are relevant to law enforcement\n",
    "\n",
    "### 3Ô∏è‚É£ **ACT** (Decision Making)\n",
    "- Use an LLM to summarize relevant articles\n",
    "- Extract key insights and implications\n",
    "\n",
    "### 4Ô∏è‚É£ **REPORT** (Output)\n",
    "- Generate a clean, actionable intelligence brief\n",
    "- Present findings in a structured format\n",
    "\n",
    "This is the **core pattern** of agentic AI‚Äîsimple but infinitely scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: FETCH - Newspaper Article Fetcher\n",
    "\n",
    "def fetch_news_articles():\n",
    "    \"\"\"\n",
    "    Fetch news headlines from multiple sources.\n",
    "    In this Stage-1 version, we use:\n",
    "    1. Mock data (for reliable demo)\n",
    "    2. Simple RSS parsing (can be enabled)\n",
    "    \n",
    "    Returns: List of article dictionaries with title, summary, and source\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mock news data (simulating real news sources)\n",
    "    # In production, replace with actual RSS feeds or news APIs\n",
    "    mock_articles = [\n",
    "        {\n",
    "            \"title\": \"Digital Arrest Scam: Mumbai Police Arrest Three in ‚Çπ2.5 Crore Fraud Case\",\n",
    "            \"summary\": \"Three individuals were arrested for impersonating police officers and threatening victims with fake digital arrest warrants. The scam targeted senior citizens, extracting large sums through fear tactics.\",\n",
    "            \"source\": \"Times of India\",\n",
    "            \"url\": \"https://example.com/article1\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Deepfake Video of Minister Goes Viral, Cybercrime Unit Investigates\",\n",
    "            \"summary\": \"A deepfake video showing a cabinet minister making controversial statements has been traced to a foreign server. Authorities are investigating the source and intent behind the manipulation.\",\n",
    "            \"source\": \"The Hindu\",\n",
    "            \"url\": \"https://example.com/article2\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"New Cricket Stadium Inaugurated in Bangalore\",\n",
    "            \"summary\": \"The state government inaugurated a new international cricket stadium with a capacity of 50,000 spectators. The facility includes modern amenities and training centers.\",\n",
    "            \"source\": \"Indian Express\",\n",
    "            \"url\": \"https://example.com/article3\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"UPI Fraud Ring Busted: 15 Arrested in Multi-State Operation\",\n",
    "            \"summary\": \"A coordinated operation across five states led to the arrest of 15 individuals involved in a sophisticated UPI fraud scheme that siphoned ‚Çπ12 crore from victims' accounts.\",\n",
    "            \"source\": \"NDTV\",\n",
    "            \"url\": \"https://example.com/article4\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Monsoon Forecast Predicts Above-Average Rainfall This Year\",\n",
    "            \"summary\": \"The meteorological department has predicted above-average monsoon rainfall for the upcoming season, bringing relief to drought-affected regions.\",\n",
    "            \"source\": \"India Today\",\n",
    "            \"url\": \"https://example.com/article5\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Cryptocurrency Ponzi Scheme Exposed: Investors Lose ‚Çπ500 Crore\",\n",
    "            \"summary\": \"An alleged cryptocurrency investment platform has been exposed as a Ponzi scheme, with thousands of investors losing their savings. The promoters remain at large.\",\n",
    "            \"source\": \"Economic Times\",\n",
    "            \"url\": \"https://example.com/article6\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Phishing Attack Targets Bank Customers: Cybersecurity Alert Issued\",\n",
    "            \"summary\": \"Major banks have issued alerts after a sophisticated phishing campaign targeted customers through fake SMS messages claiming account suspension.\",\n",
    "            \"source\": \"Business Standard\",\n",
    "            \"url\": \"https://example.com/article7\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"üì∞ Fetched {len(mock_articles)} articles from news sources\")\n",
    "    return mock_articles\n",
    "\n",
    "\n",
    "# Optional: Real RSS feed fetcher (uncomment to use)\n",
    "# def fetch_from_rss(rss_url):\n",
    "#     \"\"\"Fetch articles from an RSS feed\"\"\"\n",
    "#     try:\n",
    "#         response = requests.get(rss_url, timeout=10)\n",
    "#         soup = BeautifulSoup(response.content, 'xml')\n",
    "#         items = soup.find_all('item')\n",
    "#         \n",
    "#         articles = []\n",
    "#         for item in items[:10]:  # Limit to 10 articles\n",
    "#             articles.append({\n",
    "#                 'title': item.title.text if item.title else '',\n",
    "#                 'summary': item.description.text if item.description else '',\n",
    "#                 'source': rss_url,\n",
    "#                 'url': item.link.text if item.link else ''\n",
    "#             })\n",
    "#         return articles\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching RSS: {e}\")\n",
    "#         return []\n",
    "\n",
    "\n",
    "# Execute the fetch\n",
    "all_articles = fetch_news_articles()\n",
    "print(f\"\\n‚úÖ Stage 1 (FETCH) complete: {len(all_articles)} articles retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: THINK - Filter for Cybercrime Content\n",
    "\n",
    "def filter_cybercrime_articles(articles):\n",
    "    \"\"\"\n",
    "    Filter articles for cybercrime-related keywords.\n",
    "    \n",
    "    This is a simple keyword-based approach.\n",
    "    In Stage-2, we could use LLM-based classification for better accuracy.\n",
    "    \n",
    "    Args:\n",
    "        articles: List of article dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        List of filtered articles related to cybercrime\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cybercrime-related keywords (government intelligence focus)\n",
    "    keywords = [\n",
    "        'fraud', 'scam', 'cybercrime', 'cyber crime', 'digital arrest',\n",
    "        'deepfake', 'phishing', 'hacking', 'ransomware', 'data breach',\n",
    "        'online fraud', 'upi fraud', 'cryptocurrency scam', 'ponzi scheme',\n",
    "        'identity theft', 'cyber attack', 'malware', 'fake website'\n",
    "    ]\n",
    "    \n",
    "    filtered = []\n",
    "    \n",
    "    for article in articles:\n",
    "        # Combine title and summary for keyword matching\n",
    "        text = (article['title'] + ' ' + article['summary']).lower()\n",
    "        \n",
    "        # Check if any keyword appears in the text\n",
    "        for keyword in keywords:\n",
    "            if keyword in text:\n",
    "                article['matched_keyword'] = keyword  # Track what triggered the match\n",
    "                filtered.append(article)\n",
    "                break  # One match is enough\n",
    "    \n",
    "    print(f\"üéØ Filtered to {len(filtered)} cybercrime-related articles\")\n",
    "    print(f\"   (Removed {len(articles) - len(filtered)} irrelevant articles)\")\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "# Execute the filtering\n",
    "cybercrime_articles = filter_cybercrime_articles(all_articles)\n",
    "\n",
    "# Show what we found\n",
    "print(\"\\nüìã Cybercrime articles identified:\")\n",
    "for idx, article in enumerate(cybercrime_articles, 1):\n",
    "    print(f\"   {idx}. {article['title'][:60]}...\")\n",
    "    print(f\"      Matched keyword: '{article['matched_keyword']}'\")\n",
    "\n",
    "print(f\"\\n‚úÖ Stage 2 (THINK) complete: {len(cybercrime_articles)} relevant articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: ACT - LLM Summarization and Analysis\n",
    "\n",
    "def summarize_with_llm(article):\n",
    "    \"\"\"\n",
    "    Use an LLM to create intelligence-focused summaries.\n",
    "    \n",
    "    The LLM extracts:\n",
    "    - Key facts (who, what, where, when)\n",
    "    - Law enforcement implications\n",
    "    - Actionable insights\n",
    "    \n",
    "    Args:\n",
    "        article: Dictionary with article data\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with intelligence summary\n",
    "    \"\"\"\n",
    "    \n",
    "    if not LLM_AVAILABLE:\n",
    "        # Fallback: Return a basic summary without LLM\n",
    "        return {\n",
    "            'title': article['title'],\n",
    "            'summary': article['summary'][:150] + '...',\n",
    "            'implications': 'LLM not available - using basic summary',\n",
    "            'source': article['source']\n",
    "        }\n",
    "    \n",
    "    # Create a focused prompt for intelligence analysis\n",
    "    prompt = f\"\"\"\n",
    "You are an intelligence analyst for a government cybercrime unit.\n",
    "\n",
    "Article Title: {article['title']}\n",
    "Article Content: {article['summary']}\n",
    "Source: {article['source']}\n",
    "\n",
    "Provide a brief intelligence summary (2-3 sentences) covering:\n",
    "1. Key facts (who, what, amounts involved)\n",
    "2. Why this matters for law enforcement\n",
    "3. Any patterns or trends\n",
    "\n",
    "Keep it concise and actionable.\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use Ollama with local Llama 3.2 model\n",
    "        response = ollama.chat(\n",
    "            model='llama3.2:latest',\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'system',\n",
    "                    'content': 'You are a cybercrime intelligence analyst. Provide concise, factual analysis.'\n",
    "                },\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt\n",
    "                }\n",
    "            ],\n",
    "            options={\n",
    "                'temperature': 0.3,  # Lower temperature for factual analysis\n",
    "                'num_predict': 200   # Limit response length\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        intelligence_summary = response['message']['content'].strip()\n",
    "        \n",
    "        return {\n",
    "            'title': article['title'],\n",
    "            'summary': intelligence_summary,\n",
    "            'implications': 'Analyzed by Llama 3.2 (local)',\n",
    "            'source': article['source'],\n",
    "            'url': article['url']\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è LLM error: {e}\")\n",
    "        return {\n",
    "            'title': article['title'],\n",
    "            'summary': article['summary'],\n",
    "            'implications': 'LLM analysis failed - using original summary',\n",
    "            'source': article['source']\n",
    "        }\n",
    "\n",
    "\n",
    "# Process all filtered articles\n",
    "intelligence_summaries = []\n",
    "\n",
    "print(\"ü§ñ Analyzing articles with Llama 3.2 (local model)...\\n\")\n",
    "\n",
    "for idx, article in enumerate(cybercrime_articles, 1):\n",
    "    print(f\"   Processing {idx}/{len(cybercrime_articles)}: {article['title'][:50]}...\")\n",
    "    summary = summarize_with_llm(article)\n",
    "    intelligence_summaries.append(summary)\n",
    "\n",
    "print(f\"\\n‚úÖ Stage 3 (ACT) complete: {len(intelligence_summaries)} summaries generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: REPORT - Generate Daily Intelligence Brief\n",
    "\n",
    "def generate_intelligence_report(summaries):\n",
    "    \"\"\"\n",
    "    Generate a clean, actionable daily intelligence brief.\n",
    "    \n",
    "    This is what gets delivered to law enforcement analysts.\n",
    "    \"\"\"\n",
    "    \n",
    "    report_date = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Build the report\n",
    "    report = f\"\"\"\n",
    "{'='*80}\n",
    "    DAILY CYBERCRIME INTELLIGENCE BRIEF\n",
    "    Generated: {report_date}\n",
    "    Source: Automated Newspaper Agent (Stage-1 Prototype)\n",
    "    AI Model: Llama 3.2 (Local)\n",
    "{'='*80}\n",
    "\n",
    "üìä SUMMARY\n",
    "   ‚Ä¢ Total articles scanned: {len(all_articles)}\n",
    "   ‚Ä¢ Cybercrime incidents identified: {len(summaries)}\n",
    "   ‚Ä¢ Analysis method: {'Llama 3.2 Local LLM' if LLM_AVAILABLE else 'Keyword-based'}\n",
    "\n",
    "{'='*80}\n",
    "\n",
    "üö® KEY INCIDENTS\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Add each incident\n",
    "    for idx, summary in enumerate(summaries, 1):\n",
    "        report += f\"\"\"\n",
    "{'‚îÄ'*80}\n",
    "INCIDENT #{idx}\n",
    "{'‚îÄ'*80}\n",
    "\n",
    "üì∞ Headline:\n",
    "   {summary['title']}\n",
    "\n",
    "üîç Intelligence Summary:\n",
    "   {summary['summary']}\n",
    "\n",
    "üìå Source: {summary['source']}\n",
    "üîó URL: {summary.get('url', 'N/A')}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Add footer\n",
    "    report += f\"\"\"\n",
    "{'='*80}\n",
    "\n",
    "üìù NOTES\n",
    "   ‚Ä¢ This is an automated Stage-1 prototype using local Llama 3.2 model\n",
    "   ‚Ä¢ Human verification recommended for high-priority incidents\n",
    "   ‚Ä¢ For urgent matters, contact the Cybercrime Coordination Center\n",
    "\n",
    "{'='*80}\n",
    "End of Report\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "# Generate and display the final report\n",
    "final_report = generate_intelligence_report(intelligence_summaries)\n",
    "print(final_report)\n",
    "\n",
    "# Optionally save to file\n",
    "report_filename = f\"cybercrime_brief_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(final_report)\n",
    "\n",
    "print(f\"\\nüíæ Report saved to: {report_filename}\")\n",
    "print(\"\\n‚úÖ Stage 4 (REPORT) complete: Intelligence brief generated\")\n",
    "print(\"\\nüéâ AGENT CYCLE COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Future Enhancements (Stage-2 and Beyond)\n",
    "\n",
    "This Stage-1 prototype demonstrates the core agent pattern. Here's how we can evolve it:\n",
    "\n",
    "### **Immediate Next Steps (Stage-2)**\n",
    "- **Automation**: Schedule the agent to run every 6 hours using cron jobs or cloud functions\n",
    "- **Real RSS Feeds**: Connect to actual news sources (Times of India, The Hindu, etc.)\n",
    "- **Better Classification**: Replace keyword matching with LLM-based relevance scoring\n",
    "- **Sentiment Analysis**: Track public sentiment around cybercrime incidents\n",
    "\n",
    "### **Medium-Term (Stage-3)**\n",
    "- **Admin Dashboard**: Build a web interface for viewing reports and managing alerts\n",
    "- **Alert System**: Send notifications for high-priority incidents (email, SMS, Slack)\n",
    "- **Trend Detection**: Track recurring patterns and emerging threats over time\n",
    "- **Multi-Source Integration**: Add social media monitoring (Twitter, Reddit)\n",
    "\n",
    "### **Advanced (Stage-4 - Multi-Agent System)**\n",
    "- **Specialist Agents**: Deploy separate agents for different cybercrime types\n",
    "  - Agent 1: Financial fraud (UPI, cryptocurrency)\n",
    "  - Agent 2: Social engineering (phishing, deepfakes)\n",
    "  - Agent 3: Infrastructure attacks (ransomware, DDoS)\n",
    "- **Coordinator Agent**: Synthesizes findings from all specialist agents\n",
    "- **Vector Database**: Store and search historical intelligence reports\n",
    "- **Predictive Analytics**: Use ML to forecast cybercrime trends\n",
    "\n",
    "### **Production Deployment**\n",
    "- **API Integration**: Connect with government databases and case management systems\n",
    "- **Compliance**: Ensure data privacy and security standards (encryption, access logs)\n",
    "- **Human-in-the-Loop**: Allow analysts to provide feedback and refine agent behavior\n",
    "- **Scalability**: Deploy on cloud infrastructure (AWS, Azure, GCP) for 24/7 operation\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Principle (Ed Donner Style)**\n",
    "\n",
    "> *\"Start simple, prove value, then scale.\"*\n",
    "\n",
    "This notebook is intentionally minimal. It proves the concept works. Now we can confidently add complexity where it matters most.\n",
    "\n",
    "---\n",
    "\n",
    "**Questions? Feedback?**  \n",
    "This is a living prototype. Test it, break it, improve it. That's how great agents are built. üõ†Ô∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
