{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé≠ LLM-Based Deepfake Reasoning Agent\n",
                "\n",
                "## Government Cyber-Fraud Prevention Project\n",
                "\n",
                "### Why Deepfake Detection Matters\n",
                "\n",
                "Deepfakes have become a critical threat in **digital arrest scams**, where fraudsters impersonate:\n",
                "- Police officers\n",
                "- Government officials\n",
                "- Court judges\n",
                "- Law enforcement agents\n",
                "\n",
                "These AI-generated videos are used to:\n",
                "1. **Intimidate victims** into believing they're under investigation\n",
                "2. **Extort money** through fake legal threats\n",
                "3. **Steal personal information** under the guise of official procedures\n",
                "\n",
                "**This notebook represents a Stage-1 prototype** that uses LLM reasoning to identify suspicious videos before they can be used in scams."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü§ñ What This Agent Is (Ed Donner Style)\n",
                "\n",
                "### The Difference: Model-Based vs. Reasoning-Based Detection\n",
                "\n",
                "**Traditional Model-Based Detection:**\n",
                "- Requires thousands of labeled deepfake videos\n",
                "- Needs CNNs, temporal models, face landmark tracking\n",
                "- Takes weeks/months to train\n",
                "- High accuracy but slow to deploy\n",
                "\n",
                "**Our Reasoning-Based Agent (Stage-1):**\n",
                "- Uses an LLM to **reason** about video characteristics\n",
                "- No training required\n",
                "- Can be deployed in hours\n",
                "- Lower accuracy but provides **immediate value**\n",
                "\n",
                "### Why Start with a Reasoning Agent?\n",
                "\n",
                "> *\"Start simple, prove value, then scale.\"* ‚Äî Ed Donner\n",
                "\n",
                "This agent:\n",
                "1. **Validates the concept** quickly\n",
                "2. **Provides early warnings** while we build better models\n",
                "3. **Helps us understand** what features matter most\n",
                "4. **Buys time** to collect training data\n",
                "\n",
                "Think of it as a **smart triage system** ‚Äî not perfect, but useful enough to catch obvious fakes and flag suspicious cases for human review."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü§ñ Deepfake Detection Model\n",
                "\n",
                "This notebook uses **Hugging Face's deepfake detection model** for real video analysis.\n",
                "\n",
                "### Model: `prithivMLmods/deepfake-detector-model-v1`\n",
                "\n",
                "**Features:**\n",
                "- ‚úÖ **No API key required** - runs locally on your machine\n",
                "- ‚úÖ **Free and open-source** - available on Hugging Face\n",
                "- ‚úÖ **Vision Transformer (ViT)** - state-of-the-art architecture\n",
                "- ‚úÖ **Binary classification** - Real vs Deepfake\n",
                "- ‚úÖ **Works offline** - after initial model download\n",
                "\n",
                "### How It Works:\n",
                "\n",
                "1. **Extract frames** from the video using OpenCV\n",
                "2. **Analyze key frames** using the ViT model\n",
                "3. **Aggregate results** across multiple frames\n",
                "4. **Provide classification** with confidence score\n",
                "\n",
                "### First Run:\n",
                "The model (~400MB) will be downloaded automatically on first use. This may take a few minutes depending on your internet speed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ OpenCV available for video processing\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "e:\\github_projects\\cg_police2\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Transformers library available\n",
                        "‚úÖ Using device: CPU\n",
                        "\n",
                        "‚úÖ Libraries imported successfully\n",
                        "üìÖ Today's date: 2026-02-03\n"
                    ]
                }
            ],
            "source": [
                "# Import necessary libraries\n",
                "import os\n",
                "import json\n",
                "import numpy as np\n",
                "from datetime import datetime\n",
                "from PIL import Image\n",
                "\n",
                "# For video processing\n",
                "try:\n",
                "    import cv2\n",
                "    CV2_AVAILABLE = True\n",
                "    print(\"‚úÖ OpenCV available for video processing\")\n",
                "except ImportError:\n",
                "    print(\"‚ùå OpenCV not installed. Install with: pip install opencv-python\")\n",
                "    CV2_AVAILABLE = False\n",
                "\n",
                "# For deepfake detection model\n",
                "try:\n",
                "    from transformers import pipeline\n",
                "    import torch\n",
                "    HF_AVAILABLE = True\n",
                "    print(\"‚úÖ Transformers library available\")\n",
                "    \n",
                "    # Check if GPU is available\n",
                "    device = 0 if torch.cuda.is_available() else -1\n",
                "    device_name = \"GPU\" if device == 0 else \"CPU\"\n",
                "    print(f\"‚úÖ Using device: {device_name}\")\n",
                "except ImportError:\n",
                "    print(\"‚ùå Transformers not installed. Install with: pip install transformers torch\")\n",
                "    HF_AVAILABLE = False\n",
                "\n",
                "print(f\"\\n‚úÖ Libraries imported successfully\")\n",
                "print(f\"üìÖ Today's date: {datetime.now().strftime('%Y-%m-%d')}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîÑ Loading deepfake detection model...\n",
                        "   (First run will download ~400MB model - this may take a few minutes)\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "e:\\github_projects\\cg_police2\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--prithivMLmods--deepfake-detector-model-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
                        "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
                        "  warnings.warn(message)\n",
                        "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
                        "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [00:00<00:00, 1107.63it/s, Materializing param=vision_model.post_layernorm.weight]                      \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Model loaded successfully!\n",
                        "   Model: prithivMLmods/deepfake-detector-model-v1\n",
                        "   Device: CPU\n"
                    ]
                }
            ],
            "source": [
                "# Load the deepfake detection model\n",
                "print(\"üîÑ Loading deepfake detection model...\")\n",
                "print(\"   (First run will download ~400MB model - this may take a few minutes)\\n\")\n",
                "\n",
                "if HF_AVAILABLE:\n",
                "    try:\n",
                "        # Load the model pipeline\n",
                "        deepfake_classifier = pipeline(\n",
                "            \"image-classification\",\n",
                "            model=\"prithivMLmods/deepfake-detector-model-v1\",\n",
                "            device=device\n",
                "        )\n",
                "        \n",
                "        print(\"‚úÖ Model loaded successfully!\")\n",
                "        print(f\"   Model: prithivMLmods/deepfake-detector-model-v1\")\n",
                "        print(f\"   Device: {device_name}\")\n",
                "        MODEL_LOADED = True\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error loading model: {e}\")\n",
                "        print(\"   Make sure you have internet connection for first-time download.\")\n",
                "        MODEL_LOADED = False\n",
                "else:\n",
                "    print(\"‚ùå Cannot load model - transformers library not available\")\n",
                "    MODEL_LOADED = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìπ Frame extraction function ready\n"
                    ]
                }
            ],
            "source": [
                "def extract_frames_from_video(video_path, num_frames=10):\n",
                "    \"\"\"\n",
                "    Extract evenly spaced frames from a video for analysis.\n",
                "    \n",
                "    Args:\n",
                "        video_path: Path to the video file\n",
                "        num_frames: Number of frames to extract (default: 10)\n",
                "    \n",
                "    Returns:\n",
                "        List of PIL Images\n",
                "    \"\"\"\n",
                "    \n",
                "    if not CV2_AVAILABLE:\n",
                "        print(\"‚ùå OpenCV not available - cannot extract frames\")\n",
                "        return None\n",
                "    \n",
                "    if not os.path.exists(video_path):\n",
                "        print(f\"‚ùå Video file not found: {video_path}\")\n",
                "        return None\n",
                "    \n",
                "    try:\n",
                "        video = cv2.VideoCapture(video_path)\n",
                "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
                "        \n",
                "        if total_frames == 0:\n",
                "            print(\"‚ùå Could not read video file\")\n",
                "            return None\n",
                "        \n",
                "        # Calculate frame indices to extract\n",
                "        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
                "        \n",
                "        frames = []\n",
                "        for idx in frame_indices:\n",
                "            video.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
                "            ret, frame = video.read()\n",
                "            \n",
                "            if ret:\n",
                "                # Convert BGR to RGB\n",
                "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
                "                # Convert to PIL Image\n",
                "                pil_image = Image.fromarray(frame_rgb)\n",
                "                frames.append(pil_image)\n",
                "        \n",
                "        video.release()\n",
                "        \n",
                "        print(f\"‚úÖ Extracted {len(frames)} frames from video\")\n",
                "        return frames\n",
                "    \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error extracting frames: {e}\")\n",
                "        return None\n",
                "\n",
                "print(\"üìπ Frame extraction function ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üéØ Deepfake analysis function ready\n"
                    ]
                }
            ],
            "source": [
                "def analyze_video_for_deepfake(video_path, num_frames=10):\n",
                "    \"\"\"\n",
                "    Analyze a video for deepfake content using Hugging Face model.\n",
                "    \n",
                "    Args:\n",
                "        video_path: Path to the video file\n",
                "        num_frames: Number of frames to analyze\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary with analysis results\n",
                "    \"\"\"\n",
                "    \n",
                "    if not MODEL_LOADED:\n",
                "        return {\n",
                "            'success': False,\n",
                "            'error': 'Model not loaded. Please run the model loading cell first.'\n",
                "        }\n",
                "    \n",
                "    # Extract frames\n",
                "    print(f\"\\nüîç Extracting {num_frames} frames from video...\")\n",
                "    frames = extract_frames_from_video(video_path, num_frames)\n",
                "    \n",
                "    if not frames:\n",
                "        return {\n",
                "            'success': False,\n",
                "            'error': 'Failed to extract frames from video'\n",
                "        }\n",
                "    \n",
                "    # Analyze each frame\n",
                "    print(f\"\\nü§ñ Analyzing frames with deepfake detection model...\")\n",
                "    \n",
                "    frame_results = []\n",
                "    deepfake_scores = []\n",
                "    \n",
                "    for i, frame in enumerate(frames):\n",
                "        try:\n",
                "            # Run classification\n",
                "            result = deepfake_classifier(frame)\n",
                "            \n",
                "            # Parse result (format: [{'label': 'Fake', 'score': 0.95}, {'label': 'Real', 'score': 0.05}])\n",
                "            fake_score = next((r['score'] for r in result if 'fake' in r['label'].lower()), 0)\n",
                "            \n",
                "            frame_results.append({\n",
                "                'frame_index': i,\n",
                "                'predictions': result,\n",
                "                'deepfake_score': fake_score\n",
                "            })\n",
                "            \n",
                "            deepfake_scores.append(fake_score)\n",
                "            \n",
                "            print(f\"   Frame {i+1}/{num_frames}: {result[0]['label']} ({result[0]['score']:.2%})\")\n",
                "        \n",
                "        except Exception as e:\n",
                "            print(f\"   ‚ö†Ô∏è Error analyzing frame {i}: {e}\")\n",
                "    \n",
                "    # Aggregate results\n",
                "    avg_deepfake_score = np.mean(deepfake_scores)\n",
                "    is_deepfake = avg_deepfake_score > 0.5\n",
                "    confidence = avg_deepfake_score if is_deepfake else (1 - avg_deepfake_score)\n",
                "    \n",
                "    return {\n",
                "        'success': True,\n",
                "        'is_deepfake': is_deepfake,\n",
                "        'confidence': confidence,\n",
                "        'avg_deepfake_score': avg_deepfake_score,\n",
                "        'frames_analyzed': len(frames),\n",
                "        'frame_results': frame_results\n",
                "    }\n",
                "\n",
                "print(\"üéØ Deepfake analysis function ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìÑ Report display function ready\n"
                    ]
                }
            ],
            "source": [
                "def print_deepfake_report(video_path, result):\n",
                "    \"\"\"\n",
                "    Print a formatted deepfake analysis report.\n",
                "    \"\"\"\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"üé≠ DEEPFAKE ANALYSIS REPORT\")\n",
                "    print(\"=\"*80)\n",
                "    print(f\"\\nüìπ Video: {os.path.basename(video_path)}\")\n",
                "    \n",
                "    if not result['success']:\n",
                "        print(f\"\\n‚ùå ANALYSIS FAILED\")\n",
                "        print(f\"Error: {result['error']}\")\n",
                "        print(\"\\n\" + \"=\"*80)\n",
                "        return\n",
                "    \n",
                "    print(f\"üìä Frames Analyzed: {result['frames_analyzed']}\")\n",
                "    print(\"\\n\" + \"-\"*80)\n",
                "    \n",
                "    classification = \"DEEPFAKE\" if result['is_deepfake'] else \"REAL\"\n",
                "    confidence_pct = result['confidence'] * 100\n",
                "    \n",
                "    print(f\"\\nüéØ CLASSIFICATION: {classification}\")\n",
                "    print(f\"üìä CONFIDENCE: {confidence_pct:.1f}%\")\n",
                "    print(f\"üìà Average Deepfake Score: {result['avg_deepfake_score']:.2%}\")\n",
                "    \n",
                "    # Provide reasoning\n",
                "    print(f\"\\nüí° ANALYSIS:\")\n",
                "    if result['is_deepfake']:\n",
                "        if confidence_pct > 80:\n",
                "            print(\"   Strong indicators of deepfake manipulation detected across multiple frames.\")\n",
                "        elif confidence_pct > 60:\n",
                "            print(\"   Moderate indicators of deepfake manipulation detected.\")\n",
                "        else:\n",
                "            print(\"   Some indicators of manipulation detected, but confidence is low.\")\n",
                "    else:\n",
                "        if confidence_pct > 80:\n",
                "            print(\"   Video appears authentic with high confidence.\")\n",
                "        elif confidence_pct > 60:\n",
                "            print(\"   Video appears authentic with moderate confidence.\")\n",
                "        else:\n",
                "            print(\"   Video appears authentic, but confidence is low.\")\n",
                "    \n",
                "    # Recommendations\n",
                "    print(f\"\\n‚úÖ RECOMMENDATION:\")\n",
                "    if result['is_deepfake'] and confidence_pct > 70:\n",
                "        print(\"   ‚ö†Ô∏è HIGH RISK: Flag for immediate investigation.\")\n",
                "        print(\"   Do not trust the content. Report to authorities if used in scam.\")\n",
                "    elif result['is_deepfake'] and confidence_pct > 50:\n",
                "        print(\"   ‚ö†Ô∏è MEDIUM RISK: Recommend human review and additional verification.\")\n",
                "        print(\"   Exercise caution and verify through alternative sources.\")\n",
                "    else:\n",
                "        print(\"   ‚úÖ LOW RISK: Video appears authentic.\")\n",
                "        print(\"   Still verify source and context if used for important decisions.\")\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "\n",
                "print(\"üìÑ Report display function ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üé¨ Analyze Your Video\n",
                "\n",
                "Provide the path to your video file below.\n",
                "\n",
                "### Requirements:\n",
                "- ‚úÖ Video file must exist on your system\n",
                "- ‚úÖ Supported formats: MP4, AVI, MOV, MKV, etc.\n",
                "- ‚úÖ Model will analyze 10 frames (adjustable)\n",
                "- ‚ö†Ô∏è First run will download the model (~400MB)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìã Video Analysis Configuration:\n",
                        "   Video Path: fake_officer_call.mp4\n",
                        "   Frames to Analyze: 10\n",
                        "\n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "# ========================================\n",
                "# USER INPUT: Specify your video file\n",
                "# ========================================\n",
                "\n",
                "# Path to your video file\n",
                "VIDEO_PATH = \"fake_officer_call.mp4\"  # Change this to your video file path\n",
                "\n",
                "# Number of frames to analyze (more frames = more accurate but slower)\n",
                "NUM_FRAMES = 10\n",
                "\n",
                "print(\"üìã Video Analysis Configuration:\")\n",
                "print(f\"   Video Path: {VIDEO_PATH}\")\n",
                "print(f\"   Frames to Analyze: {NUM_FRAMES}\")\n",
                "print(\"\\n\" + \"=\"*80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üöÄ Starting deepfake analysis...\n",
                        "   This may take 30 seconds to 2 minutes depending on your hardware.\n",
                        "\n",
                        "\n",
                        "üîç Extracting 10 frames from video...\n",
                        "‚úÖ Extracted 10 frames from video\n",
                        "\n",
                        "ü§ñ Analyzing frames with deepfake detection model...\n",
                        "   Frame 1/10: Fake (54.81%)\n",
                        "   Frame 2/10: Real (53.82%)\n",
                        "   Frame 3/10: Real (50.42%)\n",
                        "   Frame 4/10: Fake (52.23%)\n",
                        "   Frame 5/10: Real (53.06%)\n",
                        "   Frame 6/10: Real (53.87%)\n",
                        "   Frame 7/10: Real (57.19%)\n",
                        "   Frame 8/10: Real (50.73%)\n",
                        "   Frame 9/10: Real (53.28%)\n",
                        "   Frame 10/10: Real (54.08%)\n",
                        "\n",
                        "================================================================================\n",
                        "üé≠ DEEPFAKE ANALYSIS REPORT\n",
                        "================================================================================\n",
                        "\n",
                        "üìπ Video: fake_officer_call.mp4\n",
                        "üìä Frames Analyzed: 10\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "\n",
                        "üéØ CLASSIFICATION: REAL\n",
                        "üìä CONFIDENCE: 51.9%\n",
                        "üìà Average Deepfake Score: 48.06%\n",
                        "\n",
                        "üí° ANALYSIS:\n",
                        "   Video appears authentic, but confidence is low.\n",
                        "\n",
                        "‚úÖ RECOMMENDATION:\n",
                        "   ‚úÖ LOW RISK: Video appears authentic.\n",
                        "   Still verify source and context if used for important decisions.\n",
                        "\n",
                        "================================================================================\n",
                        "\n",
                        "‚úÖ Analysis complete!\n",
                        "\n",
                        "‚ö†Ô∏è Note: Always verify with human review for critical decisions.\n"
                    ]
                }
            ],
            "source": [
                "# ========================================\n",
                "# RUN DEEPFAKE ANALYSIS\n",
                "# ========================================\n",
                "\n",
                "if not os.path.exists(VIDEO_PATH):\n",
                "    print(f\"\\n‚ùå Video file not found: {VIDEO_PATH}\")\n",
                "    print(\"   Please check the path and try again.\")\n",
                "else:\n",
                "    print(f\"\\nüöÄ Starting deepfake analysis...\")\n",
                "    print(f\"   This may take 30 seconds to 2 minutes depending on your hardware.\\n\")\n",
                "    \n",
                "    # Run analysis\n",
                "    result = analyze_video_for_deepfake(VIDEO_PATH, NUM_FRAMES)\n",
                "    \n",
                "    # Display report\n",
                "    print_deepfake_report(VIDEO_PATH, result)\n",
                "    \n",
                "    if result['success']:\n",
                "        print(\"\\n‚úÖ Analysis complete!\")\n",
                "        print(\"\\n‚ö†Ô∏è Note: Always verify with human review for critical decisions.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚ö†Ô∏è IMPORTANT NOTES\n",
                "\n",
                "### What This System Does:\n",
                "\n",
                "This notebook uses a **Vision Transformer (ViT) model** trained on deepfake datasets:\n",
                "- ‚úÖ **Real frame-by-frame analysis** (not just metadata)\n",
                "- ‚úÖ **No API key required** - runs completely locally\n",
                "- ‚úÖ **Works offline** - after initial model download\n",
                "- ‚úÖ **Free and open-source**\n",
                "\n",
                "### Limitations:\n",
                "\n",
                "- ‚ö†Ô∏è **Image-based detection only** - analyzes frames, not audio-visual sync\n",
                "- ‚ö†Ô∏è **Not 100% accurate** - sophisticated deepfakes may evade detection\n",
                "- ‚ö†Ô∏è **Requires GPU for speed** - CPU inference is slower\n",
                "- ‚ö†Ô∏è **Model size** - ~400MB download on first use\n",
                "- ‚ö†Ô∏è **Frame sampling** - only analyzes subset of frames (not entire video)\n",
                "\n",
                "### Accuracy:\n",
                "\n",
                "The model has been trained on common deepfake datasets and works well for:\n",
                "- ‚úÖ Face-swap deepfakes\n",
                "- ‚úÖ GAN-generated faces\n",
                "- ‚úÖ Common deepfake tools (DeepFaceLab, FaceSwap, etc.)\n",
                "\n",
                "May struggle with:\n",
                "- ‚ùå Very high-quality deepfakes\n",
                "- ‚ùå Novel deepfake techniques\n",
                "- ‚ùå Audio deepfakes (voice cloning)\n",
                "\n",
                "### Use Cases:\n",
                "\n",
                "**‚úÖ Good for:**\n",
                "- Initial screening of suspicious videos\n",
                "- Rapid triage in scam investigations\n",
                "- Educational purposes\n",
                "- Offline/air-gapped environments\n",
                "\n",
                "**‚ùå NOT suitable for:**\n",
                "- Forensic evidence without additional verification\n",
                "- 100% certainty requirements\n",
                "- Real-time video analysis\n",
                "\n",
                "### Recommendations:\n",
                "\n",
                "1. **Always verify results** with human analysts\n",
                "2. **Use multiple detection methods** for critical cases\n",
                "3. **Analyze more frames** (increase NUM_FRAMES) for better accuracy\n",
                "4. **Check audio separately** - this model only analyzes visual content\n",
                "\n",
                "---\n",
                "\n",
                "**Model**: [prithivMLmods/deepfake-detector-model-v1](https://huggingface.co/prithivMLmods/deepfake-detector-model-v1)  \n",
                "**License**: Open-source (check Hugging Face for details)  \n",
                "**Version**: 2.0 (Local Model-based)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
